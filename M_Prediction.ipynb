{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M Prediction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhshobhit2222/BadUino/blob/master/M_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P81tQOSDMyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYb69P1FETHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icOuoZY8EcwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"shobhit03\",\"key\":\"08af528b7b4919b506ed93f0b684ee10\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Hx8zvHE-S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpXxTj31FIdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg_VOXugFvm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nJiYAX_F8ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKb8xYybGOFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip cell-images-for-detecting-malaria.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3IAEc6lGX9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "base_dir = os.path.join('./cell_images')\n",
        "infected_dir = os.path.join(base_dir,'Parasitized')\n",
        "healthy_dir = os.path.join(base_dir,'Uninfected')\n",
        "\n",
        "infected_files = glob.glob(infected_dir+'/*.png')\n",
        "healthy_files = glob.glob(healthy_dir+'/*.png')\n",
        "len(infected_files),len(healthy_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw7w7Rh3TtRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "files_df = pd.DataFrame({\n",
        "    'filename': infected_files + healthy_files,\n",
        "    'label' : ['malaria']*len(infected_files) + ['no_malaria']*len(healthy_files)\n",
        "}).sample(frac=1,random_state=42).reset_index(drop=True)\n",
        "\n",
        "files_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOxMTg3YViun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "train_files,test_files,train_labels,test_labels = train_test_split(files_df['filename'].values,files_df['label'].values,test_size=0.3,random_state=42)\n",
        "\n",
        "train_files,val_files,train_labels,val_labels = train_test_split(train_files,train_labels,test_size=0.1,random_state=42)\n",
        "\n",
        "print(train_files.shape,val_files.shape,test_files.shape)\n",
        "print('Train:', Counter(train_labels),'\\nVal',Counter(val_labels), '\\nTest', Counter(test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri-FgSxvdIln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from concurrent import futures\n",
        "import threading\n",
        "\n",
        "def img_shape(idx,img,t_imgs):\n",
        "  if idx % 5000 == 0 or idx == (t_imgs -1):\n",
        "    print('{}: working on img num: {}'.format(threading.current_thread().name,idx))\n",
        "    \n",
        "  return cv2.imread(img).shape\n",
        "\n",
        "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
        "d_input = [(idx,img,len(train_files)) for idx, img in enumerate(train_files)]\n",
        "print('Starting image shape computation:')\n",
        "\n",
        "train_imgs_dims_map = ex.map(img_shape,[record[0] for record in d_input],[record[1] for record in d_input],[record[2] for record in d_input])\n",
        "train_img_dims = list(train_imgs_dims_map)\n",
        "\n",
        "print('min Dimensions:', np.min(train_img_dims, axis=0))\n",
        "print('avg Dimensions:', np.mean(train_img_dims, axis=0))\n",
        "print('median Dimensions:', np.median(train_img_dims, axis=0))\n",
        "print('max Dimensions:', np.min(train_img_dims, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba-aMaakAT6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_DIMS=(125,125)\n",
        "\n",
        "def img_data_parallel(idx,img,t_imgs):\n",
        "  if idx % 5000 == 0 or idx == (t_imgs - 1):\n",
        "        print('{}: working on img num: {}'.format(threading.current_thread().name,idx))\n",
        "      \n",
        "  img=cv2.imread(img)\n",
        "  img=cv2.resize(img,dsize=IMG_DIMS,interpolation=cv2.INTER_CUBIC)\n",
        "  img = np.array(img, dtype=np.float32)\n",
        "  return img\n",
        "\n",
        "\n",
        "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
        "train_data_inp=[(idx, img, len(train_files)) for idx, img in enumerate(train_files)]\n",
        "val_data_inp=[(idx, img, len(val_files)) for idx, img in enumerate(val_files)]\n",
        "test_data_inp=[(idx, img, len(test_files)) for idx, img in enumerate(test_files)]\n",
        "\n",
        "\n",
        "print('Loading Train Images:')\n",
        "train_data_map = ex.map(img_data_parallel, [record[0] for record in train_data_inp],[record[1] for record in train_data_inp],[record[2] for record in train_data_inp])\n",
        "train_data = np.array(list(train_data_map))\n",
        "\n",
        "print('\\nLoading Validation Images:')\n",
        "val_data_map = ex.map(img_data_parallel, [record[0] for record in val_data_inp],[record[1] for record in val_data_inp],[record[2] for record in val_data_inp])\n",
        "val_data = np.array(list(val_data_map))\n",
        "\n",
        "print('\\nLoading Test Images:')\n",
        "test_data_map = ex.map(img_data_parallel, [record[0] for record in test_data_inp],[record[1] for record in test_data_inp],[record[2] for record in test_data_inp])\n",
        "test_data = np.array(list(test_data_map))\n",
        "\n",
        "train_data.shape, val_data.shape, test_data.shape \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmavMuUYCvRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(1, figsize=(8,8))\n",
        "n=0\n",
        "for i in range(16):\n",
        "  n +=1\n",
        "  r=np.random.randint(0, train_data.shape[0],1)\n",
        "  plt.subplot(4,4,n)\n",
        "  plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
        "  plt.imshow(train_data[r[0]]/255.)\n",
        "  plt.title('{}'.format(train_labels[r[0]]))\n",
        "  plt.xticks([]) , plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWwvpQ_PIqCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 10\n",
        "INPUT_SHAPE = (125, 125, 3)\n",
        "\n",
        "train_imgs_scaled = train_data / 255.\n",
        "val_imgs_scaled = val_data / 255.\n",
        "\n",
        "# encode text category labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "train_labels_enc = le.transform(train_labels)\n",
        "val_labels_enc = le.transform(val_labels)\n",
        "\n",
        "print(train_labels[:6], train_labels_enc[:6])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAKciwoQL77b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TensorBoard notebook extension (optional)\n",
        "%load_ext tensorboard.notebook\n",
        "\n",
        "#tf.random.seed(42)\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7_T7VtiN8QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
        "                               activation='relu', padding='same')(inp)\n",
        "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), \n",
        "                               activation='relu', padding='same')(pool1)\n",
        "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), \n",
        "                               activation='relu', padding='same')(pool2)\n",
        "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flat = tf.keras.layers.Flatten()(pool3)\n",
        "\n",
        "hidden1 = tf.keras.layers.Dense(512, activation='relu')(flat)\n",
        "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
        "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
        "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
        "\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inp, outputs=out)\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_co2hGb4OWhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "logdir = os.path.join(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=2, min_lr=0.000001)\n",
        "callbacks = [reduce_lr, tensorboard_callback]\n",
        "\n",
        "history = model.fit(x=train_imgs_scaled, y=train_labels_enc, \n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, \n",
        "                    validation_data=(val_imgs_scaled, val_labels_enc), \n",
        "                    callbacks=callbacks,\n",
        "                    verbose=1)\n",
        "                    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}